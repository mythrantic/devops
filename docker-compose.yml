---
volumes:
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  ollama-data:
    driver: local
  pocketbase-data:
    driver: local

services:
  nginx:
    image: nginx:latest
    container_name: nginx-proxy
    ports:
      - 80:80
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - prometheus
      - grafana
      - node-exporter
      - cadvisor
      - uptime-kuma
      - alertmanager
      - svelte-leaflet

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - /etc/prometheus:/config
      - prometheus-data:/prometheus
      - ./ansible/roles/docker_deploy/files/prometheus/:/etc/prometheus/
    command: "--config.file=/etc/prometheus/prometheus.yml"
    restart: unless-stopped
    links:
      - cadvisor:cadvisor
      - alertmanager:alertmanager
    depends_on:
      - cadvisor
    ports:
      - 9001:9090
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - 9002:3000
    volumes:
      - grafana-data:/var/lib/grafana
      - ./ansible/roles/docker_deploy/files/grafana/:/etc/grafana/
    restart: unless-stopped
    networks:
      - monitoring

  node-exporter:
    image: quay.io/prometheus/node-exporter:latest
    container_name: node_exporter
    ports:
      - 9003:9100
    command: 
      - '--path.rootfs=/host'
    pid: host
    restart: unless-stopped
    networks:
      - monitoring
    volumes:
      - '/:/host:ro,rslave'

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - 9004:8080
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    restart: unless-stopped
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring

  uptime-kuma:
    image: louislam/uptime-kuma:1
    container_name: uptime-kuma
    ports:
      - 9005:3001
    volumes:
      - ./ansible/roles/docker_deploy/files/uptime-kuma:/app/data
    restart: always
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager
    container_name: alertmanager
    ports:
      - 9006:9093
    volumes:
      - ./ansible/roles/docker_deploy/files/alertmanager/:/etc/alertmanager/
    networks:
      - monitoring
    restart: always
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'    

  svelte-leaflet:
    image: valiantlynx/svelte-leaflet:latest
    container_name: svelte-leaflet
    restart: always
    networks:
      - monitoring
    ports:
      - 9007:3000
  chattergun:
    container_name: chattergun
    image: valiantlynx/chattergun:latest
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - chattergun-relay
    ports:
      - 9008:3000

  chattergun-relay:
    container_name: chattergun-relay
    image: valiantlynx/chattergun-relay:latest
    restart: unless-stopped
    networks:
      - monitoring
    ports:
      - 9009:8765

  recommendation-engine:
    image: valiantlynx/recommendation-engine:latest
    container_name: recommendation-engine
    restart: always
    networks:
      - monitoring
    ports:
      - 9010:3000

  ollama-docker:
    image: valiantlynx/ollama-docker:latest
    container_name: ollama-docker
    build: .
    ports:
      - 9011:8000
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
    restart: always
    depends_on:
      - ollama
      - ollama-webui
    networks:
      - ollama-docker
      
  ollama:
    container_name: ollama
    pull_policy: always
    restart: unless-stopped
    image: ollama/ollama:latest
    ports:
      - 9012:11434
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    networks:
      - ollama-docker
    volumes:
      - ollama-data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all 
              capabilities: [gpu]

  ollama-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: ollama-webui
    depends_on:
      - ollama
    ports:
      - 9013:8080
    environment: # https://docs.openwebui.com/getting-started/env-configuration#default_models
      - OLLAMA_BASE_URLS=http://192.168.38.157:9012 #comma separated ollama hosts
      - ENV=dev
      - WEBUI_AUTH=False
      - WEBUI_NAME=valiantlynx AI
      - WEBUI_URL=http://localhost:8080
      - WEBUI_SECRET_KEY=t0p-s3cr3t
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped
    networks:
      - ollama-docker

  svelte-rich-text:
    image: valiantlynx/svelte-rich-text:latest
    container_name: svelte-rich-text
    restart: always
    networks:
      - monitoring
    ports:
      - 9014:3000

  valiantos:
    image: valiantlynx/valiantos:latest
    container_name: valiantos
    restart: always
    networks:
      - monitoring
    ports:
      - 9015:3000

  raga:
    image: valiantlynx/raga:latest
    container_name: raga
    restart: always
    networks:
      - monitoring
    ports:
      - 9016:3000
    depends_on:
      - raga-backend
  raga-backend:
    image: valiantlynx/raga-backend:latest
    container_name: raga-backend
    restart: always
    networks:
      - monitoring
    ports:
      - 9017:3000

  gun-chat:
    container_name: gun-chat
    image: valiantlynx/gun-chat:latest
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - gun-relay
    ports:
      - 9018:3000

  gun-relay:
    container_name: gun-relay
    image: valiantlynx/gun-relay:latest
    restart: unless-stopped
    networks:
      - monitoring
    ports:
      - 9019:8765


  svelte-altlokalt:
    image: valiantlynx/svelte-altlokalt:latest
    container_name: svelte-altlokalt
    restart: always
    networks:
      - monitoring
    ports:
      - 9020:3000

  svelte-manga-api:
    image: valiantlynx/svelte-manga-api:latest
    container_name: svelte-manga-api
    restart: unless-stopped
    command: uvicorn src.main:app --host 0.0.0.0 --port 8000
    mem_limit: 500m
    memswap_limit: 500m
    healthcheck:
      test: ["CMD", "curl", "-f", "http://svelte-manga-api.valiantlynx.com"]
      interval: 10s
      timeout: 5s
      retries: 3
    ports:
      - 9021:8000
    networks:
      - monitoring

  svelte-manga:
    image: valiantlynx/svelte-manga:latest
    container_name: svelte-manga
    restart: always
    networks:
      - monitoring
    ports:
      - 9022:3000

  pocketbase-docker:
    image: valiantlynx/pocketbase-docker:latest
    container_name: pocketbase-docker 
    ports:
      - '9023:8080'
    restart: always
    volumes:
      - pocketbase-data:/pb_data
    networks:
      - pocketbase

networks:
  monitoring: {}
  pocketbase:
  ollama-docker:
    external: false
